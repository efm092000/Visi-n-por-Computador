{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736160589.158617  245240 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1736160589.160102  245968 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 620 (WHL GT2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python.vision.gesture_recognizer import GestureRecognizerResult\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Initialization of Mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "model_path = './gesture_recognizer.task'\n",
    "base_options = mp.tasks.BaseOptions(model_asset_path=model_path)\n",
    "\n",
    "# Configuration variables\n",
    "colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0), (0, 255, 255)]  # Red, Green, Blue, Yellow\n",
    "current_color = colors[0]\n",
    "brush_size = 10\n",
    "menu_width = 100\n",
    "drawing = False\n",
    "canvas = None\n",
    "dominant_hand = None\n",
    "calibrating = True\n",
    "frame_width = None\n",
    "frame_height = None\n",
    "current_frame = None\n",
    "processed_frame = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736160589.196943  245961 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "def draw_menu(frame):\n",
    "    for i, color in enumerate(colors):\n",
    "        cx, cy = 50, 100 + i * 100\n",
    "        cv2.circle(frame, (cx, cy), 30, color, -1)\n",
    "\n",
    "def count_visible_fingers(hand_landmarks):\n",
    "    finger_tips = [\n",
    "        mp_hands.HandLandmark.THUMB_TIP,\n",
    "        mp_hands.HandLandmark.INDEX_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.RING_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.PINKY_TIP\n",
    "    ]\n",
    "    visible_fingers = 0\n",
    "    for tip in finger_tips:\n",
    "        tip_coord = hand_landmarks[tip]\n",
    "        base_coord = hand_landmarks[tip - 2]  # Base of each finger\n",
    "        if tip_coord.y < base_coord.y:  # Finger is up if tip is above base\n",
    "            visible_fingers += 1\n",
    "    return visible_fingers\n",
    "\n",
    "def calculate_brush_size(hand_landmarks):\n",
    "    index_tip = hand_landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "    distance = math.sqrt((index_tip.x - middle_tip.x)**2 + (index_tip.y - middle_tip.y)**2)\n",
    "    return int(distance * 300)\n",
    "\n",
    "def detect_dominant_hand(result):\n",
    "    global calibrating\n",
    "    if result.hand_landmarks and result.handedness and result.gestures:\n",
    "        for hand_idx in range(len(result.hand_landmarks)):\n",
    "            hand_label = result.handedness[hand_idx][0].category_name\n",
    "            gesture_name = result.gestures[hand_idx][0].category_name\n",
    "            if gesture_name == \"Open_Palm\":\n",
    "                calibrating = False\n",
    "                return hand_label\n",
    "    return None\n",
    "\n",
    "def process_hand_interaction(frame, hand_landmarks, handedness):\n",
    "    global drawing, current_color, brush_size, canvas\n",
    "\n",
    "    # Get index finger coordinates\n",
    "    index_finger = hand_landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    x, y = int(index_finger.x * frame_width), int(index_finger.y * frame_height)\n",
    "\n",
    "    # Count visible fingers\n",
    "    visible_fingers = count_visible_fingers(hand_landmarks)\n",
    "    \n",
    "    if visible_fingers == 0:\n",
    "        drawing = False\n",
    "    else:\n",
    "        drawing = True\n",
    "        if visible_fingers == 1:\n",
    "            brush_size = 10\n",
    "        elif visible_fingers >= 2:\n",
    "            brush_size = calculate_brush_size(hand_landmarks)\n",
    "\n",
    "    # Menu interaction\n",
    "    wrist_x = int(hand_landmarks[mp_hands.HandLandmark.WRIST].x * frame_width)\n",
    "    if wrist_x < menu_width:\n",
    "        for i, color in enumerate(colors):\n",
    "            cx, cy = 50, 100 + i * 100\n",
    "            if math.hypot(x - cx, y - cy) < 30:\n",
    "                current_color = color\n",
    "    else:\n",
    "        if drawing:\n",
    "            cv2.circle(canvas, (x, y), brush_size, current_color, -1)\n",
    "\n",
    "    # Show index finger color\n",
    "    cv2.circle(frame, (x, y), 10, current_color, -1)\n",
    "\n",
    "def gesture_callback(result: GestureRecognizerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    global calibrating, dominant_hand, canvas, frame_width, frame_height, current_frame, processed_frame\n",
    "    \n",
    "    # Get the frame from the output_image\n",
    "    # frame = np.array(output_image.numpy_view()).copy()\n",
    "    frame = current_frame.copy()\n",
    "\n",
    "    if canvas is None:\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "        canvas = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    if calibrating:\n",
    "        cv2.putText(frame, \"Show your dominant hand\", (10, 50), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        if result.gestures:\n",
    "            dominant_hand = detect_dominant_hand(result)\n",
    "            if dominant_hand:\n",
    "                print('dominant hand set to', dominant_hand)\n",
    "    else:\n",
    "        if result.hand_landmarks and result.handedness:\n",
    "            for i, hand_landmarks in enumerate(result.hand_landmarks):\n",
    "                handedness = result.handedness[i][0].category_name\n",
    "                if handedness == dominant_hand:\n",
    "                    process_hand_interaction(frame, hand_landmarks, handedness)\n",
    "    \n",
    "    # Combine canvas with frame\n",
    "    frame = cv2.addWeighted(frame, 0.5, canvas, 0.5, 0)\n",
    "    draw_menu(frame)\n",
    "         \n",
    "    \n",
    "    #cv2.imshow(\"Interactive Paint\", frame)\n",
    "    processed_frame = frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736160589.218526  245960 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1736160589.224035  245240 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1736160589.225636  245971 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 620 (WHL GT2)\n",
      "W0000 00:00:1736160589.226145  245240 gesture_recognizer_graph.cc:129] Hand Gesture Recognizer contains CPU only ops. Sets HandGestureRecognizerGraph acceleration to Xnnpack.\n",
      "I0000 00:00:1736160589.227617  245240 hand_gesture_recognizer_graph.cc:250] Custom gesture classifier is not defined.\n",
      "W0000 00:00:1736160589.270989  245975 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736160589.303505  245973 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736160589.304963  245973 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736160589.305167  245973 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "[ WARN:0@95.719] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@95.720] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "# Set up gesture recognizer\n",
    "options = mp.tasks.vision.GestureRecognizerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=mp.tasks.vision.RunningMode.LIVE_STREAM,\n",
    "    result_callback=gesture_callback\n",
    ")\n",
    "recognizer = mp.tasks.vision.GestureRecognizer.create_from_options(options)\n",
    "\n",
    "# Start camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.flip(frame, 1)  # Horizontal flip for mirror effect\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Store the current frame for the callback to use\n",
    "    current_frame = frame.copy()\n",
    "    \n",
    "    # Process frame with gesture recognizer\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    current_timestamp_ms = int(time.time() * 1000)\n",
    "    recognizer.recognize_async(mp_image, current_timestamp_ms)\n",
    "\n",
    "    # Display the processed frame if available\n",
    "    if processed_frame is not None:\n",
    "        cv2.imshow(\"Interactive Paint\", processed_frame)\n",
    "    else:\n",
    "        cv2.imshow(\"Interactive Paint\", frame)\n",
    "    \n",
    "    # Check for key presses\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == 27:  # ESC to exit\n",
    "        break\n",
    "    elif key & 0xFF == ord('d'):  # Toggle drawing\n",
    "        drawing = not drawing\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
