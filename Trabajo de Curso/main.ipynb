{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736157136.433726  203972 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1736157136.449707  225208 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 620 (WHL GT2)\n"
     ]
    }
   ],
   "source": [
    "# File: interactive_paint_with_dynamic_brush.py\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python.vision.gesture_recognizer import GestureRecognizerResult\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Inicialización de Mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "model_path = './gesture_recognizer.task'\n",
    "base_options = mp.tasks.BaseOptions(model_asset_path=model_path)\n",
    "\n",
    "# Configuración de colores\n",
    "colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0), (0, 255, 255)]  # Rojo, Verde, Azul, Amarillo\n",
    "current_color = colors[0]\n",
    "brush_size = 10\n",
    "\n",
    "# Variables del menú y pintura\n",
    "menu_width = 100\n",
    "drawing = False\n",
    "canvas = None  # Para almacenar lo dibujado\n",
    "dominant_hand = None  # Será \"Left\" o \"Right\"\n",
    "calibrating = True  # Modo calibración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "def draw_menu(frame):\n",
    "    # Dibuja los colores del menú sin fondo.\n",
    "    for i, color in enumerate(colors):\n",
    "        cx, cy = 50, 100 + i * 100\n",
    "        cv2.circle(frame, (cx, cy), 30, color, -1)\n",
    "\n",
    "def count_visible_fingers(hand_landmarks):\n",
    "    # Cuenta el número de dedos visibles.\n",
    "    finger_tips = [\n",
    "        mp_hands.HandLandmark.THUMB_TIP,\n",
    "        mp_hands.HandLandmark.INDEX_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.MIDDLE_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.RING_FINGER_TIP,\n",
    "        mp_hands.HandLandmark.PINKY_TIP\n",
    "    ]\n",
    "\n",
    "    visible_fingers = 0\n",
    "    for tip in finger_tips:\n",
    "        tip_coord = hand_landmarks.landmark[tip]\n",
    "        base_coord = hand_landmarks.landmark[tip - 2]  # Base de cada dedo\n",
    "        if tip_coord.y < base_coord.y:  # Dedo levantado si la punta está por encima de la base\n",
    "            visible_fingers += 1\n",
    "\n",
    "    return visible_fingers\n",
    "\n",
    "def calculate_brush_size(hand_landmarks):\n",
    "    # Calcula el tamaño de la brocha según la distancia entre los dedos índice y medio.\n",
    "    index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "\n",
    "    # Distancia euclidiana entre los dos dedos\n",
    "    distance = math.sqrt((index_tip.x - middle_tip.x)**2 + (index_tip.y - middle_tip.y)**2)\n",
    "    return int(distance * 300)  # Escalar la distancia para que sea visible\n",
    "\n",
    "def gesture_callback(result: GestureRecognizerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    # print(result)\n",
    "\n",
    "    if not result.gestures:\n",
    "        return\n",
    "    \n",
    "    global calibrating\n",
    "    if calibrating:\n",
    "        dominant_hand = detect_dominant_hand(result)\n",
    "\n",
    "        if dominant_hand:\n",
    "            calibrating = False\n",
    "            print('dominant hand set to ', dominant_hand)\n",
    "\n",
    "\n",
    "def detect_dominant_hand(result):\n",
    "    # Detecta si la mano es izquierda o derecha.\n",
    "    if result.hand_landmarks and result.handedness and result.gestures:\n",
    "        # Check each hand\n",
    "        for hand_idx in range(len(result.hand_landmarks)):\n",
    "            hand_label = result.handedness[hand_idx][0].category_name\n",
    "            gesture_name = result.gestures[hand_idx][0].category_name\n",
    "            \n",
    "            if gesture_name == \"Open_Palm\":\n",
    "                return hand_label\n",
    "            \n",
    "    # If no hand with Open_Palm was found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736157136.643866  225201 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1736157136.664525  203972 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1736157136.668087  225211 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.0.9-0ubuntu0.2), renderer: Mesa Intel(R) UHD Graphics 620 (WHL GT2)\n",
      "W0000 00:00:1736157136.670109  203972 gesture_recognizer_graph.cc:129] Hand Gesture Recognizer contains CPU only ops. Sets HandGestureRecognizerGraph acceleration to Xnnpack.\n",
      "I0000 00:00:1736157136.676753  203972 hand_gesture_recognizer_graph.cc:250] Custom gesture classifier is not defined.\n",
      "W0000 00:00:1736157136.707322  225201 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736157136.736032  225213 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736157136.765140  225215 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736157136.765771  225217 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736157136.765858  225217 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dominant hand set to  Left\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n",
      "Paint\n"
     ]
    }
   ],
   "source": [
    "options = mp.tasks.vision.GestureRecognizerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=mp.tasks.vision.RunningMode.LIVE_STREAM,\n",
    "    result_callback=gesture_callback\n",
    ")\n",
    "recognizer = mp.tasks.vision.GestureRecognizer.create_from_options(options)\n",
    "\n",
    "# Iniciar cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if canvas is None:\n",
    "        canvas = np.zeros_like(frame)  # Inicializar el lienzo\n",
    "\n",
    "    current_timestamp_ms = int(time.time() * 1000)\n",
    "    frame = cv2.flip(frame, 1)  # Flip horizontal para parecer espejo\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    if calibrating:\n",
    "        # Mostrar mensaje para calibrar\n",
    "        cv2.putText(frame, \"Muestra tu mano dominante\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "        recognizer.recognize_async(mp_image, current_timestamp_ms)\n",
    "\n",
    "    else:\n",
    "        # Detección de manos (solo rastrear la dominante)\n",
    "        if results.multi_handedness and results.multi_hand_landmarks:\n",
    "            for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                handedness = results.multi_handedness[i].classification[0].label\n",
    "                if handedness != dominant_hand:\n",
    "                    continue  # Ignorar manos que no sean la dominante\n",
    "\n",
    "                # Coordenadas del índice\n",
    "                index_finger = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                x, y = int(index_finger.x * frame_width), int(index_finger.y * frame_height)\n",
    "\n",
    "                # Contar dedos visibles\n",
    "                visible_fingers = count_visible_fingers(hand_landmarks)\n",
    "\n",
    "                if visible_fingers == 0:\n",
    "                    # Puño cerrado, desactivar dibujo\n",
    "                    drawing = False\n",
    "                else:\n",
    "                    # Ajustar el tamaño del pincel dinámicamente\n",
    "                    drawing = True\n",
    "                    if visible_fingers == 1:\n",
    "                        brush_size = 10  # Tamaño mínimo para un dedo\n",
    "                    elif visible_fingers >= 2:\n",
    "                        brush_size = calculate_brush_size(hand_landmarks)\n",
    "\n",
    "                # Detectar interacción con el menú\n",
    "                wrist_x = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * frame_width)\n",
    "                if wrist_x < menu_width:\n",
    "                    # Cambiar color si se toca un círculo de color\n",
    "                    for i, color in enumerate(colors):\n",
    "                        cx, cy = 50, 100 + i * 100\n",
    "                        if math.hypot(x - cx, y - cy) < 30:\n",
    "                            current_color = color\n",
    "                else:\n",
    "                    # Dibujar según la posición del índice\n",
    "                    if drawing:\n",
    "                        cv2.circle(canvas, (x, y), brush_size, current_color, -1)  # Pintar\n",
    "\n",
    "                # Mostrar el color del índice\n",
    "                cv2.circle(frame, (x, y), 10, current_color, -1)  # Colorear la punta del índice\n",
    "\n",
    "    # Combinar el lienzo con el frame\n",
    "    frame = cv2.addWeighted(frame, 0.5, canvas, 0.5, 0)\n",
    "\n",
    "    # Dibujar el menú\n",
    "    draw_menu(frame)\n",
    "\n",
    "    # Mostrar el frame\n",
    "    cv2.imshow(\"Paint Interactivo\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == 27:  # Presionar ESC para salir\n",
    "        break\n",
    "    elif key & 0xFF == ord('d'):  # Activar/desactivar dibujo\n",
    "        drawing = not drawing\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
