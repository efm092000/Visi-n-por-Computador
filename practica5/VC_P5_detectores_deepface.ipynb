{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #Detección de caras con webcam usando deepface\n",
    "\n",
    "Deepface crea directorios para descargar los modelos, cuidado si tienes el disco bastante lleno. Es posible configurar la ruta, en mi caso uso  E:\\RUNNERS_code\\code\\DeepFace, tras definir la ruta a través de la variable de entorno DEEPFACE_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\efm09\\anaconda3\\envs\\VC_P5\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "# documentation https://github.com/serengil/deepface/blob/master/deepface/modules/detection.py\n",
    "# detector_backends deepface options: 'opencv', 'retinaface', 'mtcnn', 'ssd', 'dlib', 'mediapipe', 'yolov8', 'centerface' or 'skip'\n",
    "detectors = ['opencv', 'mtcnn', 'retinaface', 'ssd']\n",
    "detector_idx = 0\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Read frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        # Face detection\n",
    "        faces = DeepFace.extract_faces(frame, detector_backend=detectors[detector_idx])\n",
    "        #print(faces)\n",
    "\n",
    "        # Draw face bounding box and eyes locations\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['facial_area']['x'], face['facial_area']['y'], face['facial_area']['w'], face['facial_area']['h']\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (200, 255, 200), 2)  # Dibuja el rectángulo\n",
    "            if face['facial_area']['left_eye'] is not None:\n",
    "                cv2.circle(frame, (face['facial_area']['left_eye'][0],face['facial_area']['left_eye'][1]), 3, (0, 255, 0), 2)\n",
    "                cv2.circle(frame, (face['facial_area']['right_eye'][0],face['facial_area']['right_eye'][1]), 3, (0, 0, 255), 2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    # Mostrar el frame\n",
    "    cv2.putText(frame, f\"Detector: {detectors[detector_idx]}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    # Salir si se presiona Esc o cambia el detectr\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:  # Salir si se presiona 'q'\n",
    "        break\n",
    "    elif key == ord('d'):  # Cambiar detector si se presiona 'c'\n",
    "        detector_idx = (detector_idx + 1) % len(detectors)\n",
    "        print(f\"Cambiado a detector: {detectors[detector_idx]}\")\n",
    "\n",
    "# Liberar la captura y cerrar ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deepface y Retinaface únicamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n",
      "{'score': np.float64(0.9993576407432556), 'facial_area': [np.int64(263), np.int64(120), np.int64(381), np.int64(283)], 'landmarks': {'right_eye': [np.float32(290.87088), np.float32(184.67503)], 'left_eye': [np.float32(346.20822), np.float32(183.05429)], 'nose': [np.float32(317.26584), np.float32(213.05907)], 'mouth_right': [np.float32(298.68945), np.float32(243.83401)], 'mouth_left': [np.float32(342.78476), np.float32(242.78242)]}}\n",
      "{'score': np.float64(0.9758593440055847), 'facial_area': [np.int64(607), np.int64(160), np.int64(620), np.int64(176)], 'landmarks': {'right_eye': [np.float32(610.6664), np.float32(166.56395)], 'left_eye': [np.float32(616.6581), np.float32(166.97908)], 'nose': [np.float32(613.0729), np.float32(169.7344)], 'mouth_right': [np.float32(610.9837), np.float32(172.5034)], 'mouth_left': [np.float32(615.2486), np.float32(172.80353)]}}\n",
      "{'score': np.float64(0.9613028168678284), 'facial_area': [np.int64(578), np.int64(163), np.int64(593), np.int64(180)], 'landmarks': {'right_eye': [np.float32(583.0189), np.float32(171.29721)], 'left_eye': [np.float32(589.70483), np.float32(170.43173)], 'nose': [np.float32(586.97455), np.float32(174.559)], 'mouth_right': [np.float32(584.92035), np.float32(177.42252)], 'mouth_left': [np.float32(589.6118), np.float32(176.77084)]}}\n",
      "{'score': np.float64(0.9401609897613525), 'facial_area': [np.int64(596), np.int64(132), np.int64(610), np.int64(148)], 'landmarks': {'right_eye': [np.float32(598.8244), np.float32(138.65204)], 'left_eye': [np.float32(604.9767), np.float32(137.6458)], 'nose': [np.float32(601.7063), np.float32(141.2333)], 'mouth_right': [np.float32(600.6621), np.float32(144.88498)], 'mouth_left': [np.float32(605.14185), np.float32(144.04625)]}}\n",
      "{'score': np.float64(0.9076498746871948), 'facial_area': [np.int64(595), np.int64(164), np.int64(607), np.int64(180)], 'landmarks': {'right_eye': [np.float32(598.4483), np.float32(171.82486)], 'left_eye': [np.float32(604.0896), np.float32(171.69168)], 'nose': [np.float32(601.2983), np.float32(175.05069)], 'mouth_right': [np.float32(599.4341), np.float32(177.5275)], 'mouth_left': [np.float32(603.4746), np.float32(177.40657)]}}\n",
      "{'score': np.float64(0.9978443384170532), 'facial_area': [np.int64(235), np.int64(99), np.int64(391), np.int64(325)], 'landmarks': {'right_eye': [np.float32(263.0732), np.float32(198.2035)], 'left_eye': [np.float32(330.99832), np.float32(196.37526)], 'nose': [np.float32(285.9662), np.float32(245.46254)], 'mouth_right': [np.float32(276.86414), np.float32(276.48517)], 'mouth_left': [np.float32(329.65646), np.float32(274.51846)]}}\n",
      "{'score': np.float64(0.979979395866394), 'facial_area': [np.int64(607), np.int64(159), np.int64(620), np.int64(175)], 'landmarks': {'right_eye': [np.float32(610.64856), np.float32(166.22643)], 'left_eye': [np.float32(616.7364), np.float32(166.62729)], 'nose': [np.float32(613.1335), np.float32(169.49718)], 'mouth_right': [np.float32(610.96545), np.float32(172.33464)], 'mouth_left': [np.float32(615.29626), np.float32(172.62329)]}}\n",
      "{'score': np.float64(0.9754440188407898), 'facial_area': [np.int64(596), np.int64(132), np.int64(610), np.int64(148)], 'landmarks': {'right_eye': [np.float32(598.6608), np.float32(138.18279)], 'left_eye': [np.float32(604.4148), np.float32(137.42374)], 'nose': [np.float32(600.9826), np.float32(141.23933)], 'mouth_right': [np.float32(600.1255), np.float32(144.87985)], 'mouth_left': [np.float32(604.2981), np.float32(144.22212)]}}\n",
      "{'score': np.float64(0.9710052013397217), 'facial_area': [np.int64(578), np.int64(162), np.int64(593), np.int64(179)], 'landmarks': {'right_eye': [np.float32(582.995), np.float32(170.67744)], 'left_eye': [np.float32(589.67676), np.float32(169.85698)], 'nose': [np.float32(586.9131), np.float32(174.1205)], 'mouth_right': [np.float32(584.7892), np.float32(176.88754)], 'mouth_left': [np.float32(589.52216), np.float32(176.27043)]}}\n",
      "{'score': np.float64(0.9292139410972595), 'facial_area': [np.int64(574), np.int64(137), np.int64(586), np.int64(150)], 'landmarks': {'right_eye': [np.float32(579.321), np.float32(141.96997)], 'left_eye': [np.float32(584.479), np.float32(142.10014)], 'nose': [np.float32(582.49786), np.float32(145.12831)], 'mouth_right': [np.float32(580.0042), np.float32(147.5677)], 'mouth_left': [np.float32(583.69257), np.float32(147.71445)]}}\n",
      "{'score': np.float64(0.9998539686203003), 'facial_area': [np.int64(304), np.int64(229), np.int64(620), np.int64(450)], 'landmarks': {'right_eye': [np.float32(475.47913), np.float32(291.8314)], 'left_eye': [np.float32(516.9399), np.float32(430.77887)], 'nose': [np.float32(411.68896), np.float32(399.03937)], 'mouth_right': [np.float32(322.58817), np.float32(332.50717)], 'mouth_left': [np.float32(353.69595), np.float32(444.25534)]}}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "#from deepface import DeepFace\n",
    "from retinaface import RetinaFace\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640);\n",
    "cap.set(4,480);\n",
    "\n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    #Deepface detecta caras y se queda con primera\n",
    "    #face = DeepFace.detectFace(img_path = frame, \n",
    "    #    target_size = (224, 224), \n",
    "    #    detector_backend = backends[4]\n",
    "    #)\n",
    "\n",
    "    #Detectar múltiples (https://sefiks.com/2021/04/27/deep-face-detection-with-retinaface-in-python/)\n",
    "    #Devuelve un dict\n",
    "    faces = RetinaFace.detect_faces(frame);\n",
    "    #Si hay detecciones\n",
    "    if len(faces) > 0:\n",
    "        #Dibuja contenedor y elementos faciales\n",
    "        for idx in range(1,len(faces)+1):\n",
    "            id = 'face_' + str(idx)\n",
    "            #Muestra información de caras\n",
    "            print(faces[id])\n",
    "            #Accediendo a contenedor de la cara\n",
    "            facial_area = faces[id]['facial_area']\n",
    "            #Accediendo a datos de los elementos faciales\n",
    "            landmarks = faces[id]['landmarks']\n",
    "            #Debug\n",
    "            #print(facial_area)\n",
    "            #print(landmarks)\n",
    "            \n",
    "            #Contenedor\n",
    "            cv2.rectangle(frame, (facial_area[2], facial_area[3])\n",
    "            , (facial_area[0], facial_area[1]), (255, 255, 255), 1)\n",
    "\n",
    "            #Elementos faciales\n",
    "            cv2.circle(frame, (int(landmarks[\"left_eye\"][0]),int(landmarks[\"left_eye\"][1])), 3, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (int(landmarks[\"right_eye\"][0]),int(landmarks[\"right_eye\"][1])), 3, (0, 0, 255), -1)\n",
    "            cv2.circle(frame, (int(landmarks[\"nose\"][0]),int(landmarks[\"nose\"][1])), 3, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, (int(landmarks[\"mouth_left\"][0]),int(landmarks[\"mouth_left\"][1])), 3, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, (int(landmarks[\"mouth_right\"][0]),int(landmarks[\"mouth_right\"][1])), 3, (0, 255, 0), -1)\n",
    "     \n",
    "    #Muestra imagen\n",
    "    \n",
    "    cv2.imshow('Cam', frame)\n",
    "    \n",
    "    #Esperar por tecla o seguir\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:  # Esc\n",
    "        break\n",
    "    \n",
    "#Cerrar ventanas y cámara\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
