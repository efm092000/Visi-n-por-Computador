{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os is used for Ilka's linux :)\n",
    "#import os\n",
    "#os.environ[\"QT_QPA_PLATFORM\"] = \"xcb\"\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 499/499 items from pretrained weights\n",
      "Ultralytics 8.3.23 🚀 Python-3.10.12 torch-2.5.0+cu124 CPU (Intel Core(TM) i7-8565U 1.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.yaml, data=/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/dataset.yaml, epochs=50, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=yolo11n.pt, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jeski/uni/master/1-semester/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/labels/train.cache... 42 images, 0 backgrounds, 0 corrupt: 100%|██████████| 42/42 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jeski/uni/master/1-semester/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/labels/val.cache... 11 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      2.894      10.66      1.735         11        640: 100%|██████████| 11/11 [00:20<00:00,  1.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      2.296      7.764      1.276          5        640: 100%|██████████| 11/11 [00:17<00:00,  1.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33   0.000303     0.0303   0.000157   7.85e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      2.336      7.728      1.208         13        640: 100%|██████████| 11/11 [00:18<00:00,  1.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33    0.00152      0.152   0.000996   0.000471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      2.089      5.844      1.174          7        640: 100%|██████████| 11/11 [00:18<00:00,  1.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33    0.00182      0.182    0.00129   0.000621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      2.135      4.787      1.118          4        640: 100%|██████████| 11/11 [00:18<00:00,  1.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33    0.00212      0.212    0.00152   0.000763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      2.142      5.255      1.092          3        640: 100%|██████████| 11/11 [00:18<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33    0.00242      0.242    0.00425     0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      2.045      4.652      1.131          7        640: 100%|██████████| 11/11 [00:18<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.219     0.0303      0.012    0.00831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      2.067      4.362      1.098          7        640: 100%|██████████| 11/11 [00:18<00:00,  1.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33       0.11     0.0303     0.0181     0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      2.118      3.628      1.172          5        640: 100%|██████████| 11/11 [00:18<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33       0.11     0.0303     0.0181     0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      2.172      4.208      1.145          6        640: 100%|██████████| 11/11 [00:18<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33        0.2      0.121      0.049     0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      2.276      4.301      1.116          5        640: 100%|██████████| 11/11 [00:18<00:00,  1.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.431      0.152       0.14     0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      2.105      3.271      1.121          6        640: 100%|██████████| 11/11 [00:18<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.431      0.152       0.14     0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G      2.072      3.291      1.069          9        640: 100%|██████████| 11/11 [00:18<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.348      0.152      0.136     0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G      2.008      3.119      1.107          5        640: 100%|██████████| 11/11 [00:18<00:00,  1.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.363      0.152     0.0964     0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G      2.305      3.535      1.136          6        640: 100%|██████████| 11/11 [00:18<00:00,  1.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.363      0.152     0.0964     0.0247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G      2.061      3.256      1.115          4        640: 100%|██████████| 11/11 [00:18<00:00,  1.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.376       0.22      0.121     0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      2.056       3.16      1.042          8        640: 100%|██████████| 11/11 [00:18<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.596      0.242      0.236     0.0731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G      2.127       3.15      1.139         12        640: 100%|██████████| 11/11 [00:18<00:00,  1.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33        0.5      0.273      0.252      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G      1.854      2.955      1.016         12        640: 100%|██████████| 11/11 [00:18<00:00,  1.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33        0.5      0.273      0.252      0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G      1.744      2.652      1.004          9        640: 100%|██████████| 11/11 [00:19<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.882      0.242      0.265      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G      1.921      3.426      1.011          6        640: 100%|██████████| 11/11 [00:19<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.427      0.303      0.251      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G      1.931      2.781      1.043          5        640: 100%|██████████| 11/11 [00:18<00:00,  1.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.427      0.303      0.251      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G      2.289      4.065       1.04         10        640: 100%|██████████| 11/11 [00:18<00:00,  1.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33       0.31      0.242       0.23      0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G      1.923      2.615     0.9883          7        640: 100%|██████████| 11/11 [00:18<00:00,  1.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.503      0.242      0.245      0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G      1.735      2.704      1.015          7        640: 100%|██████████| 11/11 [00:19<00:00,  1.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.503      0.242      0.245      0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G      1.824      3.124     0.9702          6        640: 100%|██████████| 11/11 [00:18<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.617      0.293      0.301      0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G      1.682       2.29     0.9791          7        640: 100%|██████████| 11/11 [00:18<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.691      0.303      0.289      0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G      1.668      2.251      1.041          5        640: 100%|██████████| 11/11 [00:19<00:00,  1.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.691      0.303      0.289      0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G      1.791      2.735      1.024          6        640: 100%|██████████| 11/11 [00:18<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.666      0.302      0.287       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G      1.681      2.699     0.9541         11        640: 100%|██████████| 11/11 [00:18<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.899       0.27      0.302      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G      1.809      2.586      0.991          9        640: 100%|██████████| 11/11 [00:18<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.899       0.27      0.302      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G       1.69      2.176     0.9737          7        640: 100%|██████████| 11/11 [00:18<00:00,  1.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.983      0.273      0.312      0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G      1.751      2.455     0.9592         16        640: 100%|██████████| 11/11 [00:18<00:00,  1.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.986      0.273       0.31      0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G      1.725      2.407     0.9114         15        640: 100%|██████████| 11/11 [00:18<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33          1      0.273      0.309      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G      1.902        2.9     0.9971          6        640: 100%|██████████| 11/11 [00:18<00:00,  1.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33          1      0.273      0.309      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G      1.763      2.334     0.9636          5        640: 100%|██████████| 11/11 [00:19<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.712      0.273      0.309      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G      1.607      2.362     0.9367         14        640: 100%|██████████| 11/11 [00:19<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.735      0.273      0.319      0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G      1.799      2.684     0.9397          4        640: 100%|██████████| 11/11 [00:18<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.735      0.273      0.319      0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G      1.574      2.427     0.9804          4        640: 100%|██████████| 11/11 [00:18<00:00,  1.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.601      0.303       0.33      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G      1.608      2.318     0.9606         11        640: 100%|██████████| 11/11 [00:18<00:00,  1.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.658      0.364      0.363      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G       1.51      2.807     0.9004          3        640: 100%|██████████| 11/11 [00:19<00:00,  1.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.658      0.364      0.363      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G      1.554      2.453     0.9697          4        640: 100%|██████████| 11/11 [00:18<00:00,  1.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.632      0.312      0.363      0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G       1.47      2.453     0.9012          3        640: 100%|██████████| 11/11 [00:18<00:00,  1.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.899      0.271      0.351      0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G      1.457      2.095     0.8798          6        640: 100%|██████████| 11/11 [00:18<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.899      0.271      0.351      0.162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G      1.354      2.329     0.9047          8        640: 100%|██████████| 11/11 [00:18<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33       0.56      0.303      0.346      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G      1.965      3.611     0.9375          3        640: 100%|██████████| 11/11 [00:18<00:00,  1.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.899       0.27      0.342      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G      1.611          3     0.8845          3        640: 100%|██████████| 11/11 [00:18<00:00,  1.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.899       0.27      0.342      0.171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G      1.393      2.112     0.8812          3        640: 100%|██████████| 11/11 [00:19<00:00,  1.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.658      0.333      0.343      0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G        1.7      3.152     0.9697          4        640: 100%|██████████| 11/11 [00:18<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.577      0.333      0.354      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G       1.74      2.866     0.9457          6        640: 100%|██████████| 11/11 [00:19<00:00,  1.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.524      0.333      0.353      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.294 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "WARNING ⚠️ validating an untrained model YAML will result in 0 mAP.\n",
      "Ultralytics 8.3.23 🚀 Python-3.10.12 torch-2.5.0+cu124 CPU (Intel Core(TM) i7-8565U 1.80GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         11         33      0.657      0.364      0.363      0.171\n",
      "Speed: 1.7ms preprocess, 88.9ms inference, 0.0ms loss, 7.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolo11n.yaml\")  # build a new model from YAML\n",
    "# model = YOLO(\"yolo11n.pt\")  # load a pretrained model (recommended for training)\n",
    "model = YOLO(\"yolo11n.yaml\").load(\"yolo11n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/dataset.yaml\", epochs=50, imgsz=640, batch=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video.\n",
      "Processed video saved to /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof-50_epochs-track.mp4\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load your trained YOLO model\n",
    "model = YOLO(\"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/runs/detect/50-epochs/weights/best.pt\")  # Replace with the path to your trained model\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4\"  # Replace with your video file path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Set up video writer to save output (optional)\n",
    "output_path = \"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof-50_epochs-track.mp4\"  # Replace with desired output path\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Process each frame of the video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO model on the frame\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Visualize the results on the frame\n",
    "    annotated_frame = results[0].plot()  # plot() adds bounding boxes and labels to the frame\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Processed video saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 88.5ms\n",
      "video 1/1 (frame 2/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 72.6ms\n",
      "video 1/1 (frame 3/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 192.5ms\n",
      "video 1/1 (frame 4/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 73.9ms\n",
      "video 1/1 (frame 5/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 82.4ms\n",
      "video 1/1 (frame 6/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 66.4ms\n",
      "video 1/1 (frame 7/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 59.5ms\n",
      "video 1/1 (frame 8/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 95.3ms\n",
      "video 1/1 (frame 9/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 69.8ms\n",
      "video 1/1 (frame 10/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 82.5ms\n",
      "video 1/1 (frame 11/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 80.0ms\n",
      "video 1/1 (frame 12/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 96.5ms\n",
      "video 1/1 (frame 13/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 72.1ms\n",
      "video 1/1 (frame 14/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 100.1ms\n",
      "video 1/1 (frame 15/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 67.5ms\n",
      "video 1/1 (frame 16/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 63.3ms\n",
      "video 1/1 (frame 17/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 101.3ms\n",
      "video 1/1 (frame 18/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 81.7ms\n",
      "video 1/1 (frame 19/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 81.0ms\n",
      "video 1/1 (frame 20/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 65.6ms\n",
      "video 1/1 (frame 21/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 64.4ms\n",
      "video 1/1 (frame 22/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 85.4ms\n",
      "video 1/1 (frame 23/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 128.7ms\n",
      "video 1/1 (frame 24/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 67.7ms\n",
      "video 1/1 (frame 25/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 86.8ms\n",
      "video 1/1 (frame 26/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 83.8ms\n",
      "video 1/1 (frame 27/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 64.6ms\n",
      "video 1/1 (frame 28/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 71.2ms\n",
      "video 1/1 (frame 29/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 4 license plates, 126.0ms\n",
      "video 1/1 (frame 30/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 64.4ms\n",
      "video 1/1 (frame 31/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 65.6ms\n",
      "video 1/1 (frame 32/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 72.4ms\n",
      "video 1/1 (frame 33/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 7 license plates, 79.2ms\n",
      "video 1/1 (frame 34/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 6 license plates, 64.2ms\n",
      "video 1/1 (frame 35/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 66.2ms\n",
      "video 1/1 (frame 36/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 61.4ms\n",
      "video 1/1 (frame 37/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 63.4ms\n",
      "video 1/1 (frame 38/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 4 license plates, 60.3ms\n",
      "video 1/1 (frame 39/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 61.6ms\n",
      "video 1/1 (frame 40/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 63.5ms\n",
      "video 1/1 (frame 41/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 4 license plates, 80.3ms\n",
      "video 1/1 (frame 42/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 65.1ms\n",
      "video 1/1 (frame 43/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 65.0ms\n",
      "video 1/1 (frame 44/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 81.5ms\n",
      "video 1/1 (frame 45/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 4 license plates, 60.9ms\n",
      "video 1/1 (frame 46/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 4 license plates, 59.2ms\n",
      "video 1/1 (frame 47/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 64.6ms\n",
      "video 1/1 (frame 48/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 77.4ms\n",
      "video 1/1 (frame 49/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 61.1ms\n",
      "video 1/1 (frame 50/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 87.7ms\n",
      "video 1/1 (frame 51/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 4 license plates, 65.4ms\n",
      "video 1/1 (frame 52/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 63.1ms\n",
      "video 1/1 (frame 53/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 96.3ms\n",
      "video 1/1 (frame 54/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 88.5ms\n",
      "video 1/1 (frame 55/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 85.2ms\n",
      "video 1/1 (frame 56/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 113.8ms\n",
      "video 1/1 (frame 57/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 84.7ms\n",
      "video 1/1 (frame 58/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 92.3ms\n",
      "video 1/1 (frame 59/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 85.2ms\n",
      "video 1/1 (frame 60/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 68.0ms\n",
      "video 1/1 (frame 61/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 65.5ms\n",
      "video 1/1 (frame 62/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 88.8ms\n",
      "video 1/1 (frame 63/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 66.0ms\n",
      "video 1/1 (frame 64/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 63.4ms\n",
      "video 1/1 (frame 65/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 99.4ms\n",
      "video 1/1 (frame 66/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 62.6ms\n",
      "video 1/1 (frame 67/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 76.0ms\n",
      "video 1/1 (frame 68/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 61.1ms\n",
      "video 1/1 (frame 69/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 62.1ms\n",
      "video 1/1 (frame 70/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 61.7ms\n",
      "video 1/1 (frame 71/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 3 license plates, 72.7ms\n",
      "video 1/1 (frame 72/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 60.7ms\n",
      "video 1/1 (frame 73/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 62.9ms\n",
      "video 1/1 (frame 74/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 58.6ms\n",
      "video 1/1 (frame 75/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 60.5ms\n",
      "video 1/1 (frame 76/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 63.0ms\n",
      "video 1/1 (frame 77/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 101.6ms\n",
      "video 1/1 (frame 78/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 65.5ms\n",
      "video 1/1 (frame 79/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 79.3ms\n",
      "video 1/1 (frame 80/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 59.3ms\n",
      "video 1/1 (frame 81/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 58.9ms\n",
      "video 1/1 (frame 82/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 85.0ms\n",
      "video 1/1 (frame 83/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 75.4ms\n",
      "video 1/1 (frame 84/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 74.7ms\n",
      "video 1/1 (frame 85/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 78.4ms\n",
      "video 1/1 (frame 86/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 77.7ms\n",
      "video 1/1 (frame 87/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 82.9ms\n",
      "video 1/1 (frame 88/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 74.4ms\n",
      "video 1/1 (frame 89/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 94.3ms\n",
      "video 1/1 (frame 90/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 68.5ms\n",
      "video 1/1 (frame 91/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 66.7ms\n",
      "video 1/1 (frame 92/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 55.7ms\n",
      "video 1/1 (frame 93/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 81.4ms\n",
      "video 1/1 (frame 94/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 62.8ms\n",
      "video 1/1 (frame 95/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 2 license plates, 59.8ms\n",
      "video 1/1 (frame 96/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 60.9ms\n",
      "video 1/1 (frame 97/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 60.5ms\n",
      "video 1/1 (frame 98/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 86.7ms\n",
      "video 1/1 (frame 99/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 60.9ms\n",
      "video 1/1 (frame 100/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 55.5ms\n",
      "video 1/1 (frame 101/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 65.1ms\n",
      "video 1/1 (frame 102/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 73.7ms\n",
      "video 1/1 (frame 103/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 65.2ms\n",
      "video 1/1 (frame 104/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 58.7ms\n",
      "video 1/1 (frame 105/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 56.4ms\n",
      "video 1/1 (frame 106/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 58.2ms\n",
      "video 1/1 (frame 107/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 57.1ms\n",
      "video 1/1 (frame 108/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 61.1ms\n",
      "video 1/1 (frame 109/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 63.6ms\n",
      "video 1/1 (frame 110/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 80.3ms\n",
      "video 1/1 (frame 111/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 99.4ms\n",
      "video 1/1 (frame 112/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 73.8ms\n",
      "video 1/1 (frame 113/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 86.0ms\n",
      "video 1/1 (frame 114/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 84.1ms\n",
      "video 1/1 (frame 115/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 68.1ms\n",
      "video 1/1 (frame 116/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 66.6ms\n",
      "video 1/1 (frame 117/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 72.3ms\n",
      "video 1/1 (frame 118/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 72.1ms\n",
      "video 1/1 (frame 119/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 72.2ms\n",
      "video 1/1 (frame 120/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 69.9ms\n",
      "video 1/1 (frame 121/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 66.4ms\n",
      "video 1/1 (frame 122/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 170.6ms\n",
      "video 1/1 (frame 123/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 125.1ms\n",
      "video 1/1 (frame 124/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 65.9ms\n",
      "video 1/1 (frame 125/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 86.8ms\n",
      "video 1/1 (frame 126/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 96.0ms\n",
      "video 1/1 (frame 127/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 60.0ms\n",
      "video 1/1 (frame 128/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 56.2ms\n",
      "video 1/1 (frame 129/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 62.9ms\n",
      "video 1/1 (frame 130/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 1 license plate, 63.6ms\n",
      "video 1/1 (frame 131/2832) /home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4: 384x640 (no detections), 67.0ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m out \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(output_path, cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp4v\u001b[39m\u001b[38;5;124m\"\u001b[39m), fps, (frame_width, frame_height))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Iterate through each frame in the video for tracking\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m results \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Get the annotated frame\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     annotated_frame \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mplot()  \u001b[38;5;66;03m# Adds bounding boxes and labels to the frame\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Write the annotated frame to the output video\u001b[39;00m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:601\u001b[0m, in \u001b[0;36mModel.track\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[1;32m    600\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:554\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/engine/predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:57\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 57\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/engine/predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/engine/predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:465\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 465\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/nn/tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/nn/tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/nn/tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py:332\u001b[0m, in \u001b[0;36mConcat.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass for the YOLOv8 mask Proto module.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/runs/detect/50-epochs/weights/best.pt\")  # Replace with your model path\n",
    "\n",
    "# Specify the input and output video paths\n",
    "video_path = \"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4\"  # Replace with your input video path\n",
    "output_path = \"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-vid-prof.mp4\"  # Path to save the annotated video\n",
    "\n",
    "# Open the input video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties for output video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (frame_width, frame_height))\n",
    "\n",
    "# Iterate through each frame in the video for tracking\n",
    "for results in model.track(source=video_path, stream=True):\n",
    "    # Get the annotated frame\n",
    "    annotated_frame = results.plot()  # Adds bounding boxes and labels to the frame\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "# Release the resources\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Annotated video saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/runs/detect/train/weights/best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the trained YOLO model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/runs/detect/train/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with the path to your trained model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[1;32m      8\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/Our-Images/train/images/1729779190271.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your image\u001b[39;00m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/models/yolo/model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:145\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/engine/model.py:285\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    282\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/nn/tasks.py:910\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    909\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 910\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/nn/tasks.py:837\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m    835\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 837\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/ultralytics/utils/patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/sem/vc/Visi-n-por-Computador/.venv/lib/python3.10/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/runs/detect/train/weights/best.pt'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/selfmadeYOLO/runs/detect/train/weights/best.pt\")  # Replace with the path to your trained model\n",
    "\n",
    "# Load the image\n",
    "image_path = \"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/datasets/Our-Images/train/images/1729779190271.jpg\"  # Replace with the path to your image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image.\")\n",
    "    exit()\n",
    "\n",
    "# Run YOLO model on the image\n",
    "results = model(image)\n",
    "\n",
    "# Visualize the results on the image\n",
    "annotated_image = results[0].plot()  # plot() adds bounding boxes and labels to the image\n",
    "\n",
    "# Display the result\n",
    "#cv2.imshow(\"YOLO Detection\", annotated_image)\n",
    "\n",
    "# Wait for a key press to close the window\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# Save the result (optional)\n",
    "output_path = \"/home/jeski/sem/vc/Visi-n-por-Computador/practica4/test-1.jpg\"  # Specify where to save the result\n",
    "cv2.imwrite(output_path, annotated_image)\n",
    "print(f\"Annotated image saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
